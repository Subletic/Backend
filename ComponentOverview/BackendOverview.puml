@startuml Backend-Overview

package "Controllers" {
    class ClientExchangeController {
        + ClientExchangeController(subtitleExporterService:ISubtitleExporterService, avReceiverService:IAvReceiverService)
        + <<async>> Get() : Task
    }
    ControllerBase <|-- ClientExchangeController
    ClientExchangeController --> "avReceiverService" IAvReceiverService
    ClientExchangeController --> "subtitleExporterService" ISubtitleExporterService
    class CustomDictionaryController {
        + CustomDictionaryController(dictionaryService:ICustomDictionaryService)
        + UploadCustomDictionary(transcriptionConfig:StartRecognitionMessage_TranscriptionConfig) : IActionResult
    }
    ControllerBase <|-- CustomDictionaryController
    CustomDictionaryController --> "dictionaryService" ICustomDictionaryService
    class SpeechBubbleController {
        + SpeechBubbleController(speechBubbleListService:ISpeechBubbleListService, applicationLifetime:IHostApplicationLifetime)
        + HandleUpdatedSpeechBubble(receivedList:SpeechBubbleChainJson) : IActionResult
        + HandleRestartRequest() : IActionResult
        + {static} ParseFrontendResponseToSpeechBubbleList(receivedList:SpeechBubbleChainJson) : List<SpeechBubble>
    }
    ControllerBase <|-- SpeechBubbleController
    SpeechBubbleController --> "speechBubbleListService" ISpeechBubbleListService
    SpeechBubbleController --> "applicationLifetime" IHostApplicationLifetime
}

package "Data-Classes and DTOs" {
    class AdditionalVocab {
        + content : string <<get>> <<set>>
        + sounds_like : List<string>? <<get>> <<set>>
        + AdditionalVocab(content:string, sounds_like:List<string>?)
    }
    class AudioQueue {
        - <<const>> MAX_QUEUE_COUNT : int = 120
        + AudioQueue(outPipe:PipeWriter)
        + <<async>> Enqueue(audioBuffer:short[]) : Task
        + <<async>> Dequeue() : Task
    }
    AudioQueue --> "outPipe" PipeWriter
    class Dictionary {
        + Dictionary(startRecognitionMessageTranscriptionConfig:StartRecognitionMessage_TranscriptionConfig)
    }
    Dictionary --> "StartRecognitionMessageTranscriptionConfig" StartRecognitionMessage_TranscriptionConfig
    class SpeechBubble {
        + SpeechBubble(id:long, speaker:int, startTime:double, endTime:double, wordTokens:List<WordToken>)
        + Id : long <<get>> <<init>>
        + Speaker : int <<get>> <<set>>
        + StartTime : double <<get>> <<set>>
        + EndTime : double <<get>> <<set>>
    }
    SpeechBubble --> "CreationTime" DateTime
    struct SpeechBubbleChainJson {
        + SpeechbubbleChain : List<SpeechBubbleJson>? <<get>> <<set>>
        + SpeechBubbleChainJson(postSpeechBubblesList:List<SpeechBubbleJson>)
    }
    struct SpeechBubbleJson {
        + Id : long <<get>> <<init>>
        + Speaker : int <<get>> <<set>>
        + StartTime : double <<get>> <<set>>
        + EndTime : double <<get>> <<set>>
        + SpeechBubbleJson(id:long, speaker:int, startTime:double, endTime:double, wordTokens:List<WordToken>)
    }
    class WordToken {
        + WordToken(word:string, confidence:float, startTime:double, endTime:double, speaker:int)
        + Word : string <<get>> <<set>>
        + Confidence : float <<get>> <<set>>
        + StartTime : double <<get>> <<set>>
        + EndTime : double <<get>> <<set>>
        + Speaker : int <<get>> <<set>>
    }

    class AddTranscriptMessage {
        + AddTranscriptMessage(format:string, metadata:AddTranscriptMessage_Metadata, results:List<AddTranscriptMessage_Result>)
        - <<const>> MESSAGE_TYPE : string = "AddTranscript"
        + message : string <<get>> <<set>>
        + format : string <<get>> <<set>>
    }
    AddTranscriptMessage --> "metadata" AddTranscriptMessage_Metadata
    class AudioAddedMessage {
        + AudioAddedMessage(seq_no:ulong)
        - <<const>> MESSAGE_TYPE : string = "AudioAdded"
        + message : string <<get>> <<set>>
        + seq_no : ulong <<get>> <<set>>
    }
    class EndOfStreamMessage {
        + EndOfStreamMessage(last_seq_no:ulong)
        - <<const>> MESSAGE_TYPE : string = "EndOfStream"
        + message : string <<get>> <<set>>
        + last_seq_no : ulong <<get>> <<set>>
    }
    class EndOfTranscriptMessage {
        + EndOfTranscriptMessage()
        - <<const>> MESSAGE_TYPE : string = "EndOfTranscript"
        + message : string <<get>> <<set>>
    }
    class ErrorMessage {
        + ErrorMessage(code:int?, type:string, reason:string)
        - <<const>> MESSAGE_TYPE : string = "Error"
        + message : string <<get>> <<set>>
        + code : int? <<get>> <<set>>
        + type : string <<get>> <<set>>
        + reason : string <<get>> <<set>>
    }
    class InfoMessage {
        + InfoMessage(code:int?, type:string, reason:string, quality:string?)
        - <<const>> MESSAGE_TYPE : string = "Info"
        + message : string <<get>> <<set>>
        + code : int? <<get>> <<set>>
        + type : string <<get>> <<set>>
        + reason : string <<get>> <<set>>
        + quality : string? <<get>> <<set>>
    }
    class RecognitionStartedMessage {
        + RecognitionStartedMessage(id:string, language_pack_info:RecognitionStartedMessage_LanguagePackInfo)
        - <<const>> MESSAGE_TYPE : string = "RecognitionStarted"
        + message : string <<get>> <<set>>
        + id : string <<get>> <<set>>
    }
    RecognitionStartedMessage --> "language_pack_info" RecognitionStartedMessage_LanguagePackInfo
    class StartRecognitionMessage {
        + StartRecognitionMessage(audio_format:StartRecognitionMessage_AudioFormat?, transcription_config:StartRecognitionMessage_TranscriptionConfig?)
        - <<const>> MESSAGE_TYPE : string = "StartRecognition"
        + message : string <<get>> <<set>>
    }
    StartRecognitionMessage --> "audio_format" StartRecognitionMessage_AudioFormat
    StartRecognitionMessage --> "transcription_config" StartRecognitionMessage_TranscriptionConfig
    class WarningMessage {
        + WarningMessage(code:int?, type:string, reason:string, duration_limit:ulong?)
        - <<const>> MESSAGE_TYPE : string = "Info"
        + message : string <<get>> <<set>>
        + code : int? <<get>> <<set>>
        + type : string <<get>> <<set>>
        + reason : string <<get>> <<set>>
        + duration_limit : ulong? <<get>> <<set>>
    }
    class AddTranscriptMessage_Metadata {
        + AddTranscriptMessage_Metadata(transcript:string, start_time:double, end_time:double)
        + transcript : string <<get>> <<set>>
        + start_time : double <<get>> <<set>>
        + end_time : double <<get>> <<set>>
    }
    class AddTranscriptMessage_Result {
        + AddTranscriptMessage_Result(type:string, start_time:double, end_time:double, is_eos:bool?, attaches_to:string?, alternatives:List<AddTranscriptMessage_Result_Alternative>?)
        + type : string <<get>> <<set>>
        + start_time : double <<get>> <<set>>
        + end_time : double <<get>> <<set>>
        + is_eos : bool? <<get>> <<set>>
        + attaches_to : string? <<get>> <<set>>
        + alternatives : List<AddTranscriptMessage_Result_Alternative>? <<get>> <<set>>
    }
    class RecognitionStartedMessage_LanguagePackInfo {
        + RecognitionStartedMessage_LanguagePackInfo(adapted:bool, itn:bool, language_description:string, word_delimiter:string, writing_direction:string)
        + adapted : bool <<get>> <<set>>
        + itn : bool <<get>> <<set>>
        + language_description : string <<get>> <<set>>
        + word_delimiter : string <<get>> <<set>>
        + writing_direction : string <<get>> <<set>>
    }
    class StartRecognitionMessage_AudioFormat {
        + StartRecognitionMessage_AudioFormat(type:string, encoding:string?, sample_rate:int?)
        - audioType : string?
        - audioEncoding : string?
        - audioSampleRate : int?
        + type : string <<get>> <<set>>
        + encoding : string? <<get>> <<set>>
        + sample_rate : int? <<get>> <<set>>
        + GetCheckedSampleRate() : int
        + GetEncodingInFFMpegFormat() : string
        + GetBytesPerSample() : uint
    }
    class StartRecognitionMessage_TranscriptionConfig {
        - <<const>> MAX_ADDITIONAL_VOCAB_COUNT : int = 1000
        + StartRecognitionMessage_TranscriptionConfig(language:string, enable_partials:bool?, additional_vocab:List<AdditionalVocab>?)
        + language : string <<get>> <<set>>
        + enable_partials : bool? <<get>> <<set>>
    }
    class AddTranscriptMessage_Result_Alternative {
        + AddTranscriptMessage_Result_Alternative(content:string, confidence:double, language:string?, speaker:string?)
        + content : string <<get>> <<set>>
        + confidence : double <<get>> <<set>>
        + language : string? <<get>> <<set>>
        + speaker : string? <<get>> <<set>>
    }
}

package "Services" {
    class AvProcessingService <<partial>> {
        - {static} <<readonly>> urlRecognitionTemplate : string = "wss://neu.rt.speechmatics.com/v2/de"
        - {static} <<partial>> messageTypeRegex() : Regex
        - apiKey : string?
        - sentNum : ulong
        - seqNum : ulong
        + AvProcessingService(wordProcessingService:IWordProcessingService, sendingAudioService:FrontendAudioQueueService)
        - {static} logSend(message:string) : void
        - {static} logReceive(message:string) : void
        - {static} deserializeMessage(buffer:string, messageName:string, descriptionOfMessage:string) : T
        + Init(apiKeyVar:string) : bool
        - {static} <<async>> sendStartRecognition(wsClient:ClientWebSocket) : Task<bool>
        - <<async>> processAudioToStream(avStream:Stream, audioPipe:PipeWriter) : Task<bool>
        - <<async>> sendAudio(wsClient:ClientWebSocket, avStream:Stream) : Task<bool>
        - <<async>> sendEndOfStream(wsClient:ClientWebSocket) : Task<bool>
        - handleSpeechmaticsResponse(responseString:string) : bool
        - <<async>> receiveMessages(wsClient:ClientWebSocket) : Task<bool>
        + <<async>> TranscribeAudio(avStream:Stream) : Task<bool>
    }
    IAvProcessingService <|-- AvProcessingService
    AvProcessingService o-> "audioFormat" StartRecognitionMessage_AudioFormat
    AvProcessingService o-> "jsonOptions" JsonSerializerOptions
    AvProcessingService --> "wordProcessingService" IWordProcessingService
    AvProcessingService --> "frontendAudioQueueService" FrontendAudioQueueService
    AvProcessingService o-> "audioMuxingPipe" Pipe
    AvProcessingService o-> "audioQueue" AudioQueue
    class AvReceiverService {
        - <<const>> MAXIMUM_READ_SIZE : int = 4096
        + AvReceiverService(avProcessingService:IAvProcessingService)
        + <<async>> Start(webSocket:WebSocket, ctSource:CancellationTokenSource) : Task
    }
    IAvReceiverService <|-- AvReceiverService
    AvReceiverService --> "avProcessingService" IAvProcessingService
    class BufferTimeMonitor {
        - <<readonly>> timeLimitInMinutes : int
        - <<readonly>> delayMilliseconds : int
        + BufferTimeMonitor(configuration:IConfiguration, hubContext:IHubContext<CommunicationHub>, speechBubbleListService:ISpeechBubbleListService, subtitleExporterService:ISubtitleExporterService)
        # <<override>> <<async>> ExecuteAsync(stoppingToken:CancellationToken) : Task
        - <<async>> deleteSpeechBubbleMessageToFrontend(id:long) : Task
    }
    BackgroundService <|-- BufferTimeMonitor
    BufferTimeMonitor --> "speechBubbleListService" ISpeechBubbleListService
    BufferTimeMonitor --> "subtitleExporterService" ISubtitleExporterService
    BufferTimeMonitor --> "configuration" IConfiguration
    class CustomDictionaryService {
        + CustomDictionaryService()
        + ProcessCustomDictionary(customDictionary:Dictionary) : void
        + GetCustomDictionaries() : List<Dictionary>
    }
    ICustomDictionaryService <|-- CustomDictionaryService
    class FrontendAudioQueueService {
        + <<new>> Enqueue(item:short[]) : void
    }
    interface IAvProcessingService {
        + Init(apiKeyVar:string) : bool
        + TranscribeAudio(avStream:Stream) : Task<bool>
    }
    interface IAvReceiverService {
        + Start(webSocket:WebSocket, ctSource:CancellationTokenSource) : Task
    }
    interface ICustomDictionaryService {
        ProcessCustomDictionary(customDictionary:Dictionary) : void
        GetCustomDictionaries() : List<Dictionary>
    }
    interface ISpeechBubbleListService {
        + GetSpeechBubbles() : LinkedList<SpeechBubble>
        + AddNewSpeechBubble(speechBubble:SpeechBubble) : void
        + DeleteOldestSpeechBubble() : void
        + ReplaceSpeechBubble(speechBubble:SpeechBubble) : void
    }
    interface ISubtitleConverter {
        + ConvertSpeechBubble(speechBubble:SpeechBubble) : void
    }
    interface ISubtitleExporterService {
        + Start(webSocket:WebSocket, ctSource:CancellationTokenSource) : Task
        + ExportSubtitle(speechBubble:SpeechBubble) : Task
    }
    interface IWordProcessingService {
        + HandleNewWord(wordToken:WordToken) : void
    }
    class SpeechBubbleListService {
        + SpeechBubbleListService()
        + GetSpeechBubbles() : LinkedList<SpeechBubble>
        + AddNewSpeechBubble(speechBubble:SpeechBubble) : void
        + DeleteOldestSpeechBubble() : void
        + ReplaceSpeechBubble(speechBubble:SpeechBubble) : void
    }
    ISpeechBubbleListService <|-- SpeechBubbleListService
    class StartupService {
        - <<const>> SPEECHMATICS_API_KEY_ENVVAR : string = "SPEECHMATICS_API_KEY"
        + StartupService(avProcessingService:IAvProcessingService)
        + StartAsync(cancellationToken:CancellationToken) : Task
        + StopAsync(cancellationToken:CancellationToken) : Task
    }
    IHostedService <|-- StartupService
    StartupService --> "avProcessingService" IAvProcessingService
    class SubtitleExporterService {
        - <<const>> MAXIMUM_READ_SIZE : int = 4096
        + SubtitleExporterService()
        + <<async>> Start(webSocket:WebSocket, ctSource:CancellationTokenSource) : Task
        + ExportSubtitle(speechBubble:SpeechBubble) : Task
    }
    ISubtitleExporterService <|-- SubtitleExporterService
    SubtitleExporterService --> "subtitleConverter" ISubtitleConverter
    class WebVttConverter {
        + WebVttConverter(outputStream:Stream)
        + ConvertSpeechBubble(speechBubble:SpeechBubble) : void
        - {static} convertToWebVttFormat(speechBubble:SpeechBubble) : string
        - {static} FormatTime(time:double) : string
        - <<async>> WriteToStream(content:string) : void
    }
    ISubtitleConverter <|-- WebVttConverter
    WebVttConverter --> "outputStream" Stream
    class WordProcessingService {
        - nextSpeechBubbleId : long
        - currentSpeaker : int?
        + WordProcessingService(hubContext:IHubContext<CommunicationHub>, speechBubbleListService:ISpeechBubbleListService)
        + HandleNewWord(wordToken:WordToken) : void
        - speechBubbleFull(wordToken:WordToken) : bool
        - <<async>> flushBufferToNewSpeechBubble() : void
        - setSpeakerIfSpeakerIsNull(wordToken:WordToken) : void
        - <<async>> sendNewSpeechBubbleMessageToFrontend(speechBubble:SpeechBubble) : Task
    }
    IWordProcessingService <|-- WordProcessingService
    WordProcessingService --> "speechBubbleListService" ISpeechBubbleListService
}

package "SignalR-Hub" {
    class CommunicationHub {
        + CommunicationHub(sendingAudioService:FrontendAudioQueueService)
        + <<async>> ReceiveAudioStream(cancellationToken:CancellationToken) : IAsyncEnumerable<short[]>
    }
    Hub <|-- CommunicationHub
    CommunicationHub --> "sendingAudioService" FrontendAudioQueueService
}



@enduml
